---
title: "Bayesian Linear Regression "
description: |
  A new article created using the Distill format.
author:
  - name: Nora Jones 
    url: https://example.com/norajones
    affiliation: Spacely Sprockets
    affiliation_url: https://example.com/spacelysprokets
date: "`r Sys.Date()`"
output: distill::distill_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# 2) Bayesian Linear Regression 

## Fit

### Make data

Use

$$
f(x) = -0.3 + 0.5 x
$$
```{r}
make_X <- 
  function(n) {
    runif(n,-1,1)
  }

a0 <- -0.3 # the true values (unknown to model)
a1 <-  0.5

sigma <- 0.2
beta  <- 1/sigma^2  # precision

make_Y <- 
  function(xs) {
    a0 + a1*xs + rnorm(length(xs),0,sigma)
  }

set.seed(121) 
X <- make_X(25) # make some points
Y <- make_Y(X)
```


```{r}
plot(X, Y)
```

### Teory

We are gonna use the following information

$$
p(w|t) = N(w|m_N,S_N)
$$
Where we have

$$
m_S = S_N(S_0^{-1}m_0+\beta \phi^Ty)\\
S_N^{-1}=S_0^{-1}+\beta\phi^T\phi

$$

For the next path I am gonna create a function that is handling the paramter updates,
where it will recive a new data point (x,y) and the previouse parameter

```{r}
one <- function(x) rep(1,length(x))
id  <- function(x) x
sq  <- function(x) x^2
x3  <- function(x) x^3
x4  <- function(x) x^4
```


```{r}
# uses linear regression basis (phi) by default 
compute_posterior <- 
  function(X, Y, m_old, S_old, phi= c(one, id) ) {
    Phi <- sapply(phi, function(base) base(X))  # make design matrix
    
    if(length(X)==1)  # type hack, with just 1 point, R makes a vector, not a matrix
      Phi <- t(as.matrix(Phi))                               
    
    
    S_new <- solve(solve(S_old) + beta * t(Phi) %*% Phi)
    m_new <- S_new %*% (solve(S_old) %*% m_old + beta * t(Phi) %*% Y)
    
    list(m=m_new, S=S_new)  # return the new updated parameters
  }
```

```{r}
alpha <- 2.0
m_0 <- c(0,0)         # we know the mean is (0,0), otherwise, center first
S_0 <- alpha * diag(2)  # relatively uninformative prior
```


```{r}
posterior_1 <- compute_posterior(X, Y, m_0, S_0, phi= c(x4, id))
posterior_1
```

```{r}
plot(X, Y, pch=19, col="black")
abline(posterior_1$m, col="red", lwd=2)
```

More points so we can update the model:

```{r}
X_new <- make_X(100) # more points are available!
Y_new <- make_Y(X_new)

posterior_2 <- compute_posterior(X_new,  Y_new, posterior_1$m, posterior_1$S)
posterior_2$m
```

```{r}
plot(c(X,X_new),
     c(Y,Y_new),
     type="n")

legend("topleft",
       c("true fit","1st fit","2nd fit"), 
       col = c("green","grey","red"), 
       lty = 1,
       lwd = 2) 

points(X,
       Y,
       pch=19,
       col="black")

points(X_new, 
       Y_new, 
       pch=19,
       col="blue")

abline(posterior_1$m, 
       col="grey")  # old fit

abline(posterior_2$m, 
       col="red")   # new fit

abline(c(-0.3,.5), 
       col="green") 
```

## Predictive Distribution

In regressin we wish to predict a continouse output in the form of
a dependent variable, often called `y` given a new datapoint from ´x´. 
This i given by the **predictive distribution**

$$
p(y|t, \alpha, \beta) = \int p(y|w,\beta) p(w|t,\alpha,\beta)d w
$$
Where the Gaussian result is:

$$
p(t|x, t,\alpha, \beta) = N(t|m_N^T\phi(x), \sigma_N^T(x))
$$
Where we have:

$$
\sigma_N^T(x)=\beta^{-1}+\phi^T(x)S_N\phi(x)
$$

```{r}
# return the predictive distribution's mean and 95% density interval
get_predictive_vals <- 
  function(x, m_N, S_N, phi) {
    
    phix <- sapply(phi, function(base) base(x))
    mean_pred <- t(m_N) %*% phix
    sd_pred  <- sqrt(1/beta + t(phix) %*% S_N %*% phix)
    
    c(mean_pred, mean_pred-2*sd_pred, mean_pred+2*sd_pred)
  }

```

```{r}
draw_predictive <- 
  function(xs, m_N, S_N, phi) {
    
    vs <- rep(NA, length(xs))
    ys <- data.frame(means=vs, p2.5=vs, p97.5=vs)  # init dataframe
    
    for (i in 1:length(xs)) {  # compute predictive values for all xs
      ys[i,] <- get_predictive_vals(xs[i],m_N, S_N, phi)
    }
    
    # draw mean and 95% interval
    lines(xs, ys[,1], col="red", lwd=2)
    lines(xs, ys[,2], col="red", lty="dashed")
    lines(xs, ys[,3], col="red", lty="dashed")
  }
```

```{r}
set.seed(121) 
X <- make_X(25) # make some points
Y <- make_Y(X)

phi <- c(one,id,sq,x3) # basis for the cubic regression
m_0 <- c(0,0,0,0)      # priors
S_0 <- alpha*diag(4) 

posterior_1 <- compute_posterior(X, Y, m_0, S_0, phi=phi)
m_N <- posterior_1$m
S_N <- posterior_1$S

plot(X, Y, pch=20, ylim=c(-1.5,1), xlim=c(-1,1), ylab="y", xlab="x")
xs <- seq(-1,1,len=50)
draw_predictive(xs, m_N, S_N, phi=phi)
```


```{r}
X_new <- make_X(50) # more points are available!
Y_new <- make_Y(X_new)

posterior_2 <- 
  compute_posterior(X_new, Y_new, posterior_1$m, posterior_1$S, phi=phi)

m_N <- posterior_2$m

S_N <- posterior_2$S

plot(c(X,X_new), c(Y,Y_new), pch=20, ylim=c(-1.5,1), xlim=c(-1,1), ylab="y", xlab="x")
draw_predictive(xs, m_N, S_N, phi=phi)
```

