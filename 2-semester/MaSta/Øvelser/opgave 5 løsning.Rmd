---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 2.11: Let the random variable X have a Cauchy distribution with pdf f (x) = 1∕(π(1 + (x − 𝜃)2)) for −∞ < x < ∞.

## a) Show that the mean of X does not exist.


## b) Moregenerally,willE[Xk]exist?(k=1,2,3,...). c) Show that 𝜃 is the median of the distribution.

# 4.32: Let X1,X2,...,X10 ∼ Pois(3). Let X = i=1 Xi. Find the pdf for the sampling distribution of X.



# 5.2:  Consider the samples 1, 3, 4, and 6 from some distribution.

## a) For one random bootstrap sample, find the probability that the mean is 1.

## b) For one random bootstrap sample, find the probability that the maximum is 6.

## c) For one random bootstrap sample, find the probability that exactly two elements in the sample are less than 2.


# 6.2: Prove Proposition 6.1.2.

# 6.4: Let X1, X2, ... , Xn be a random sample from the distribution with pdf f (x; 𝜃) = (x3e−x∕𝜃)∕(6𝜃4) for x ≥ 0. Calculate the maximum likelihood estimate of 𝜃.

# 6.12: Let X1, X2 be random sample from N(𝜇, 32) and Y1, Y2 be a random sample from N(2𝜇,32), and assume the X′s are independent of the Y′s. ij SupposeX1 =3,X2 =−1,Y1 =3,Y2 =2.Find the MLE of𝜇.


# 5.3:  Consider the samples 1–3.

> I 5.3 menes med ”samples 1–3” at vi ser pa en stikprøve sim indeholder værdierne 1,2 ˚
og 3. Til begge opgaver findes korte svar i bogen (side 516).


## a) List all the (ordered) bootstrap samples from this sample. How many are there?

3 i 3

## b) How many unordered bootstrap samples are there? For example, {1, 2, 2} and {2, 1, 2} are considered to be the same.

unored og brugr 2 a minus n og får 10 forskellige udtryk

## c) How many ordered bootstrap samples have one occurrence of 1 and two occurrences of 3? Is this the same number of bootstrap samples that have each of 1, 2, and 3 occurring exactly once?

 

## d) Is the probability of obtaining a bootstrap sample with one 1 and two 3’s the same as the probability of obtaining a bootstrap sample with each of 1, 2, and 3 occurring exactly once?



# 5.5

# 5A Fordelingsmodeller i praksis

Denne opgave omhandler valg af en passende fordelingsmodel. Mulige kandidater er:
familier af binomial-, negative binomial-, geometriske, Poisson, normal-, og eksponentialfordelinger.

## a) I et call center overvages indgåaende opkald mellem kl. 10:00 og kl. 11:00. Der registreres tidspunkterne, og om kunden var sur eller glad, da vedkommende ringede. I alt besvarede call centret 48 opkald. Desværre kom 32 fra sure kunder. Lad være med at regne - angiv bare, hvilken fordelingsfamilie du vælger, for at beskrive

### antallet af indgaende opkald mellem kl. 10:20 og kl. 10:25, ˚

poisson, da antallet er diskret og tilfældigt fordelt.

### ventetiden mellem første og andet opkald i tidsrummet 10:00 – 11:00,

eksponential, ventiden mellem to event.

### antal af sure kunder blandt de første 20 der ringede,

binomial, sur = fiasko, glad = succes

### antal af sure opkald indtil den første venlige opkald.

geometrisk, antal indtil succes.

## b) Angiv eksempler pa situationer, hvor du ville bruge et af de resterende fordelingsmod eller (ud over dem du har brugt i pkt (a).

Normal kunne beskrive ventetiden mellem all opkald i perioden.
negativ binomial kunne være antall af opkald indtil 4 succeser.  

# 6.10 MLE  

![](6.10.png)

$$
L(\mu|x=95,y=130)=\frac{1}{15\cdot \sqrt(2\pi)}e^{-\frac{(95-\mu)^2}{2*15^2}} \cdot 
\frac{1}{30\cdot \sqrt(2\pi)}e^{-\frac{(130-1.3\cdot \mu)^2}{2*20^2}}
$$

differentiere og sæt lig med nul og vi får
$$
\mu = 97.44
$$

# 6.16 Let the five numbers 2, 3, 5, 9, 10 come from the uniform distribution on [𝛼, 𝛽]. Find the method of moments estimates of 𝛼 and 𝛽.

vi skal bruge en metode hvor vi regne sample momen og den teoretisk for til
sidst at løse lignignerne.

- sample moment

$$
\frac{1}{5}(2 + 3 +5+9+10)=5.8
$$

- sample moment

$$
\frac{1}{5}(2^2 + 3^2 +5^2+9^2+10^2)=43.8
$$

- teoretisk momen

$$
E[X]=\int^B_a x \frac{1}{B-a} dx = \frac{b^2-a^2}{2(b-a)}
$$
- teoretisk moment
$$
E[X]=\int^B_a x^2 \frac{1}{B-a} dx = \frac{b^3-a^3}{4(b-a)}
$$

løser ligningsystem

$$
\frac{b^2-a^2}{2(b-a)}=5.8
$$

$$
\frac{b^3-a^3}{3(b-a)}=54.8

$$
doven og får

$$
\alpha = 0.28 \\ \beta = 11.32
$$

# 6.30 bias estimator

![](6.30.png)

Vi husker at $\bar X$ er en unbiased estimator for mu.
Lad $h(x)=5x^2$. Vi vil gerne vise, at $h(\bar X)$ er en biased estimator for $h(\mu)$.
Vi vil altså vise $E(h(\bar X))\neq h(\mu)$

$$
E(h(\bar X)) =E(5\bar X^2) \\
= 5E(\bar X^2)\\
= 5(var(\bar X)+E(\bar X)^2) \\
= 5(\frac{\sigma^2}{n} + \mu^2)
$$
bruger theorem 5.4 at estimator for stik prøve variansen er ovenståene. 
Vi får ikke h(mu) derfor er den biased. 

Vi ser det ønskede af ovenstående. Vi kan dog bemærke at for n -> infty vil 
ovenstående gå mod 5mu^2 = h(mu). Så asymptotisk er h(bar X) en unbiaed estimator
for h(mu), da sigma2/n hvor n vil gå mod nul og derfor får vi 5mu.


# 6.34 mse ad smaller estimator

![](6.34.png)

### a) 

find mindst mse, var + bias^2

udregn bias

$$
B(\hat \theta_1) = \theta - \theta =0 \\
MSE(\hat \theta_1) = 25
$$
$$
B(\hat \theta_2) = \theta + 3 - \theta = 3 \\
MSE(\hat \theta_1) = 4 + 3^2 = 13
$$

theta2 er er med mindst fejl.

### b) 

Her skal vi isoler b

$$
25 > 4+b^2\longrightarrow \\
21>b^2 \longrightarrow \\
0\le b\le\sqrt(21)
$$

# random opgave

```{r}
n <- 16
curve(x*(1-x)/n, from = 0,
      to = 1,
      xlab = "p",
      ylab = "mse")

curve(n*(1-x)*x/(n+2)^2 + (1-2*x)^2/(n+2)^2, add = TRUE, col = "blue", lty=2)
```

når n er 16 er der en forskel på mse, men jo højere vi kommer op desto mere
konvergere den mod den først så clt.

Er den konsisten? betyder at den også konvergere med en hvis sandsynlighed.
Brug her proposition 6.3.4

![](6.3.4.png)

I kapitel 6 som Eskild gennegår ser vi bare desto større n bliver vil vi få
den samme fordeling. Husk proposition 6.3.4.


# 5.B: Consider a population that has a normal distribution with mean 𝜇 = 36, standard deviation 𝜎 = 8

## a) The sampling distribution of X for samples of size 200 will have what mean, standard error, and shape

## b) Use R to draw a random sample of size 200 from this population. Conduct EDA on your sample

## c) Compute the bootstrap distribution for your sample, and note the bootstrap mean and standard error.

## d) Compare the bootstrap distribution to the theoretical sampling distribution by creating a table like Table 5.2

## e) Repeat for sample sizes of n = 50 and n = 10. Carefully describe your observations about the effects of sample size on the bootstrap distribution


# 5.9: Consider a population that has a gamma distribution with parameters r = 5, 𝜆 = 1∕4.

## a) Use simulation (with n = 200) to generate an approximate sampling distribution of the mean; plot and describe the distribution.

```{r}
set.seed(1234)
n = 200
N = 10^4 # 10000 gange
Xbar = numeric(N)

for (i in 1:N){
  sample <- rgamma(n, shape = 5, rate = 1/4)
  Xbar[i] <- mean(sample)
}

mean(Xbar)
```

```{r}
sd(Xbar)
```

```{r}
hist(Xbar)
```

Det ser normal fordelt ud. Det er der et theorem der siger.


## b) Now, draw one random sample of size 200 from this population.Create a histogram of your sample, and find the mean and standard deviation

Tag et eksempel

```{r}
sample <- rgamma(n, 5, 1/4)

mean(sample)
sd(sample)
```

```{r}
hist(sample)
```

Det ser mere ud til at være en gamem fordeling.


## c) Compute the bootstrap distribution of the mean for your sample, plot it, and note the bootstrap mean and standard error.

```{r}
N = 10^4

bootstrapXbar = numeric(N)

for (i in 1:N){
  bootstrap <- sample(sample, n, replace = TRUE)
  bootstrapXbar[i] <- mean(bootstrap)
}
mean(bootstrapXbar)
```

```{r}
sd(bootstrapXbar)
```

Vi tager det ud fra en stikprøve og ikke populationen. Det er essens af bootstrap.

```{r}
hist(bootstrapXbar)
```

Vi ser det konvergere mod en normal fordeling. 



## d) Compare the bootstrap distribution to the approximate theoretical sampling distribution by creating a table like Table 5.2.

```{r}
pop_mean <- 5/(1/4)
pop_sd <- sqrt(5/(1/4)^2)
tbl <- matrix(c(pop_mean, 
                pop_sd, 
                mean(Xbar),
                sd(Xbar),
                mean(sample),
                sd(sample),
                mean(bootstrapXbar), 
                sd(bootstrapXbar)),
                nrow = 4,
                byrow = TRUE)

rownames(tbl) <- c("Population", "Sampling distribution of Xbar",
                   "Sample", "Bootstrap districution")
colnames(tbl) <- c("mean", "std")
tbl
```

sætter middel værdi og st op mod hianden. 
De minder om hinanden bootstrap, sample og pop. 

## e) Repeat (a)–(e) for sample sizes of n = 50 and n = 10. Describe care- fully your observations about the effects of sample size on the bootstrap distribution



# 5.13: The data set FishMercury contains mercury levels (parts per million) for 30 fish caught in lakes in Minnesota.

## a) Create a histogram or boxplot of the data. What do you observe?

```{r}
fish <- read.csv("MatStat-R/data/FishMercury.csv")
boxplot(fish)
```

Der er en outlier.



## b) Bootstrap the mean, and record the bootstrap standard error and the 95% bootstrap percentile interval.

```{r}
set.seed(1234)
data <- fish$Mercury
nsim <- 1000
xbar <- numeric(nsim)

# sample

for (i in 1:nsim) {
  bootdata <- sample(data, replace = TRUE)
  xbar[i] <- mean(bootdata)
}

mean(xbar)
sd(xbar)

quantile(xbar, probs = c(0.025, 0.975))
hist(xbar)
```

vi får standard erro, mean og konfidens bånd. Så vi ser den rigtig værdi ligger i intervallet. 
VI ser også histogrammet

## c) Remove the outlier and bootstrap the mean of the remaining data. Record the bootstrap standard error and the 95% bootstrap percentile interval.

```{r}
library(tidyverse)
library(magrittr)
fish_modified <- fish %>% filter(Mercury < max(Mercury))

boxplot(fish_modified)
```

Den ser pæner ud og er mere normal fordelt.

##d) What effect did removing the outlier have on the bootstrap distribu- tion, in particular, the standard error?

```{r}
set.seed(1234)
data <- fish_modified$Mercury
nsim <- 1000
xbar <- numeric(nsim)

# sample

for (i in 1:nsim) {
  bootdata <- sample(data, replace = TRUE)
  xbar[i] <- mean(bootdata)
}

mean(xbar)
sd(xbar)

quantile(xbar, probs = c(0.025, 0.975))
hist(xbar)
```

sd er mindre. Det sammes. 

I bootstrop tager man stikprøver af sin stikprøver. 



# 6.14 

![](6.14.png)
Vi har at $X_1,..,X_n\sim Gamma(r,\lambda)$
med pdf $f(x)=\frac{\lambda^r}{\Gamma(r)}x^{r-1}e^{-\lambda x}$

Vores likelihood funktion er givet ved

![](6.14løsnign.png)
gamme fordeling som vi skal finde estimer r og lambda.
vi skal finde log lieklihood estimator.
opstil log likelihood.
når vi har den skal vi på 158 definere for hver parameter og sæt lig nul
og læs ligninsystemet. 
log likeligho er et produkt af pdf. 
Summer er letter at arbejde med. 